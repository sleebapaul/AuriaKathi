{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.48\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Workspace and Datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace Auria is loaded\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "#ws = Workspace.from_config(\"../config2.json\")\n",
    "print(\"Workspace {} is loaded\".format(ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob azureml-blobstore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a auria5226806917\n",
      "workspacefilestore AzureFile azureml-filestore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a auria5226806917\n",
      "videos AzureBlob videos happypathspublic\n",
      "models AzureBlob styletransfer pipelinedata\n",
      "breeds AzureBlob azureml-blobstore-315a742f-5c1f-465a-9486-7fd50bbb0012 danielscstoragebhmgfqha\n",
      "images_datastore AzureBlob sampledata pipelinedata\n",
      "auria5226806917__azureml_blobstore_963d160e_9bdd_40a8_852c_1fc06dfe7c7a AzureBlob azureml-blobstore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a auria5226806917\n",
      "auria9030644229__azureml_blobstore_af014520_168f_4d68_ab72_dbc070080caf AzureBlob azureml-blobstore-af014520-168f-4d68-ab72-dbc070080caf auria9030644229\n",
      "auria5226806917__revisions AzureBlob revisions auria5226806917\n",
      "minxia2storagexujmxsjn__azureml_blobstore_4e82210c_3a29_4f15_b59e_aabe71978be3 AzureBlob azureml-blobstore-4e82210c-3a29-4f15-b59e-aabe71978be3 minxia2storagexujmxsjn\n"
     ]
    }
   ],
   "source": [
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type, ds.container_name, ds.account_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datastore account - auria5226806917\n",
    "\n",
    "# Datastore name (Blob) - azureml-blobstore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a\n",
    "\n",
    "# Datastore name (File) - azureml-filestore-963d160e-9bdd-40a8-852c-1fc06dfe7c7a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List out the compute engines available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing6854\n",
      "demo-dogbreeds\n",
      "adftest\n",
      "gpuclusterNCv2\n",
      "gpuclusterNCv3\n",
      "cpucluster\n",
      "v100cluster1\n",
      "gpucluster\n",
      "cpu-cluster\n",
      "gpu-cluster\n"
     ]
    }
   ],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting compute target with each compute engine\n",
    "\n",
    "# Using gpuclusterNCv2 for compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: cpucluster\n",
      "Found existing compute target: gpuclusterNCv2\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "Created new compute target: gpuclusterNCv3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "# CPU Cluster\n",
    "cpu_compute_target = \"cpucluster\"\n",
    "\n",
    "try:\n",
    "    cpu_compute = AmlCompute(ws, cpu_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(cpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 0,\n",
    "                                                                max_nodes = 4)\n",
    "    cpu_compute = AmlCompute.create(ws, cpu_compute_target, provisioning_config)\n",
    "    cpu_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(cpu_compute.name))\n",
    "\n",
    "# GPU Cluster\n",
    "gpu_compute_target_1 = \"gpuclusterNCv2\"\n",
    "\n",
    "try:\n",
    "    gpu_compute_1 = AmlCompute(ws, gpu_compute_target_1)\n",
    "    print(\"Found existing compute target: {}\".format(gpu_compute_1.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6S_V2\",\n",
    "                                                                min_nodes = 0,\n",
    "                                                                max_nodes = 4)\n",
    "    gpu_compute_1 = AmlCompute.create(ws, gpu_compute_target_1, provisioning_config)\n",
    "    gpu_compute_1.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(gpu_compute_1.name))\n",
    "    \n",
    "    \n",
    "gpu_compute_target_2 = \"gpuclusterNCv3\"\n",
    "\n",
    "try:\n",
    "    gpu_compute_2 = AmlCompute(ws, gpu_compute_target_2)\n",
    "    print(\"Found existing compute target: {}\".format(gpu_compute.name))\n",
    "except:\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6S_V3\",\n",
    "                                                                min_nodes = 0,\n",
    "                                                                max_nodes = 4)\n",
    "    gpu_compute_2 = AmlCompute.create(ws, gpu_compute_target_2, provisioning_config)\n",
    "    gpu_compute_2.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    print(\"Created new compute target: {}\".format(gpu_compute_2.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "fs = Datastore.get(ws, datastore_name='workspacefilestore')\n",
    "blob_storage = Datastore.get(ws, datastore_name='workspaceblobstore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the pipeline \n",
    "\n",
    "# Step 1 - Generate poem from finetuned GPT-2 Model\n",
    "\n",
    "# Mapping the data reference of trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_lang_model = DataReference(\n",
    "    datastore=fs,\n",
    "    data_reference_name=\"finetunedGPTModel\",\n",
    "    path_on_datastore=\"finetunedGPTModel/run1\")\n",
    "\n",
    "generatedHaiku = PipelineData(name=\"generatedHaiku\", \n",
    "                            datastore=blob_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genHaikuStep step created\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.pipeline.steps import MpiStep\n",
    "\n",
    "project_folder = \"../Auria/gpt-2-finetuning/\"\n",
    "\n",
    "genHaikuEst = Estimator(source_directory=project_folder,\n",
    "                         compute_target=gpu_compute_target_1,\n",
    "                         entry_script='generateFromGPT.py',\n",
    "                         node_count=1,\n",
    "                         process_count_per_node=1,\n",
    "                         pip_packages=[ \"gpt-2-simple\", \"numpy\", \"tensorflow-gpu==1.13.1\"],\n",
    "                         custom_docker_image = \"sleebapaul/cuda_10_0_cudnn_7_conda:ubuntu\",\n",
    "                         use_gpu=True)\n",
    "genHaikuEst._estimator_config.environment.python.user_managed_dependencies=False\n",
    "\n",
    "\n",
    "est_step = EstimatorStep(name=\"Estimator_GPT_generation\", \n",
    "                         estimator=genHaikuEst, \n",
    "                         estimator_entry_script_arguments=[\"--run_name\", trained_lang_model, \n",
    "                                                           \"--output_folder\", generatedHaiku],\n",
    "                         runconfig_pipeline_params=None, \n",
    "                         inputs=[trained_lang_model], \n",
    "                         outputs=[generatedHaiku], \n",
    "                         compute_target=gpu_compute_target_1,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "print(\"genHaikuStep step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom docker image - sleebapaul/cuda_10_0_cudnn_7_conda:ubuntu\n",
    "\n",
    "# pip packages used - gpt-2-simple, numpy, tensorflow-gpu==1.13.1\n",
    "\n",
    "# Input - trained_lang_model\n",
    "\n",
    "# Output - generatedHaiku \n",
    "\n",
    "# Project folder - gpt-2-finetuning\n",
    "\n",
    "# Script name - generateFromGPT.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step two \n",
    "\n",
    "# Generating the image from text \n",
    "\n",
    "# Mapping data references \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_AttnGAN2 = DataReference(\n",
    "    datastore=blob_storage,\n",
    "    data_reference_name=\"coco_AttnGAN2\",\n",
    "    path_on_datastore=\"sleebaBlobs/coco_AttnGAN2.pth\")\n",
    "\n",
    "image_encoder100 = DataReference(\n",
    "    datastore=blob_storage,\n",
    "    path_on_datastore=\"sleebaBlobs/image_encoder100.pth\")\n",
    "\n",
    "text_encoder100 = DataReference(\n",
    "    datastore=blob_storage,\n",
    "    data_reference_name=\"text_encoder100\",\n",
    "    path_on_datastore=\"sleebaBlobs/text_encoder100.pth\")\n",
    "\n",
    "data_dir = DataReference(\n",
    "    datastore=fs,\n",
    "    data_reference_name=\"coco\",\n",
    "    path_on_datastore=\"coco\")\n",
    "\n",
    "\n",
    "generatedArt = PipelineData(name=\"generatedArt\", datastore=blob_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'distributed_backend' parameter will be deprecated. Please use 'distributed_training' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textToImageStep step created\n"
     ]
    }
   ],
   "source": [
    "project_folder = \"../Auria/attnGAN/\"\n",
    "\n",
    "nodecount_param = PipelineParameter(name=\"nodecount\", default_value=3)\n",
    "\n",
    "cd = CondaDependencies()\n",
    "cd.add_channel(\"conda-forge\")\n",
    "cd.add_channel(\"pytorch\")\n",
    "cd.add_conda_package(\"pytorch\")\n",
    "cd.add_conda_package(\"torchvision\")\n",
    "\n",
    "# Runconfig\n",
    "amlcompute_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "amlcompute_run_config.environment.docker.enabled = True\n",
    "amlcompute_run_config.environment.docker.gpu_support = True\n",
    "amlcompute_run_config.environment.docker.base_image = \"pytorch/pytorch\"\n",
    "amlcompute_run_config.environment.spark.precache_packages = False\n",
    "\n",
    "textToImageStep = MpiStep(\n",
    "    name=\"text_to_image_step\",\n",
    "    script_name=\"gen_art.py\",\n",
    "    arguments=[\"--gpu\", 0,  \n",
    "               \"--data_dir\", data_dir, \n",
    "               \"--model_path\", coco_AttnGAN2,\n",
    "               \"--textencoder_path\", text_encoder100,\n",
    "               \"--input_text_folder\", generatedHaiku,\n",
    "               \"--output_dir\", generatedArt\n",
    "              ],\n",
    "    inputs=[data_dir, coco_AttnGAN2, text_encoder100, generatedHaiku],\n",
    "    outputs=[generatedArt],\n",
    "    compute_target=gpu_compute_1,\n",
    "    node_count=nodecount_param, \n",
    "    process_count_per_node=1,\n",
    "    pip_packages=[\"mpi4py\", \"torch\", \"torchvision\", \"numpy\", \"pyyaml\", \"nltk\",\"easydict\",\"pandas\", \"Pillow\" ,\"scikit-image\"],\n",
    "    source_directory=project_folder,\n",
    "    runconfig=amlcompute_run_config,\n",
    "    use_gpu=True,\n",
    "    allow_reuse=False)\n",
    "\n",
    "print(\"textToImageStep step created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step three\n",
    "\n",
    "# Photo styling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataReference object created\n"
     ]
    }
   ],
   "source": [
    "photo_wct = DataReference(\n",
    "    datastore=blob_storage,\n",
    "    data_reference_name=\"photo_wct\",\n",
    "    path_on_datastore=\"sleebaBlobs/photo_wct.pth\")\n",
    "\n",
    "wikiart_emotions = DataReference(\n",
    "    datastore=fs,\n",
    "    data_reference_name=\"WikiArt_Emotions\",\n",
    "    path_on_datastore=\"WikiArt-Emotions\")\n",
    "\n",
    "coloredImage = PipelineData(name=\"coloredImage\", \n",
    "                                    datastore=blob_storage)\n",
    "\n",
    "print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coloring step created\n"
     ]
    }
   ],
   "source": [
    "project_folder = \"../Auria/NVIDIAFastPhotoStyle/\"\n",
    "\n",
    "coloringEst = Estimator(source_directory=project_folder,\n",
    "                      compute_target=gpu_compute_target_1,\n",
    "                      entry_script='demo.py',\n",
    "                      node_count=1,\n",
    "                      process_count_per_node=1,\n",
    "                      pip_packages=[ \"http://download.pytorch.org/whl/cu91/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\", \n",
    "                                    \"torchvision==0.2.1\", \"scikit-umfpack\", \"setuptools\", \"numpy\",\"Pillow\", \"scipy==1.1.0\",\n",
    "                                    \"pynvrtc==9.1\", \"cupy-cuda91\"],\n",
    "                      custom_docker_image = \"sleebapaul/cuda_9_1_conda:ubuntu\",\n",
    "                      use_gpu=True)\n",
    "coloringEst._estimator_config.environment.python.user_managed_dependencies=False\n",
    "\n",
    "\n",
    "coloringeEstStep = EstimatorStep(name=\"Estimator_coloring_step\", \n",
    "                         estimator=coloringEst, \n",
    "                         estimator_entry_script_arguments=[\"--content_image_path\", generatedArt, \n",
    "                                                           \"--model_path\", photo_wct,\n",
    "                                                          \"--style_image_path\", wikiart_emotions,\n",
    "                                                          \"--output_image_path\", coloredImage],\n",
    "                         runconfig_pipeline_params=None, \n",
    "                         inputs=[photo_wct, wikiart_emotions, generatedArt], \n",
    "                         outputs=[coloredImage], \n",
    "                         compute_target=gpu_compute_target_1,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "print(\"Coloring step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "# Setting up the pipeline with 3 steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built\n",
      "Step Estimator_GPT_generation is ready to be created [2276a757]\n",
      "Step text_to_image_step is ready to be created [011807ad]\n",
      "Step Estimator_coloring_step is ready to be created [d0777e9c]\n",
      "Pipeline validation complete\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "steps = [est_step, textToImageStep, coloringeEstStep]\n",
    "\n",
    "auria_pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "print(\"Pipeline is built\")\n",
    "\n",
    "auria_pipeline.validate()\n",
    "print(\"Pipeline validation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Estimator_GPT_generation [2276a757][219d944f-8755-424d-9bcd-4ca953d2bc2a], (This step will run and generate new outputs)\n",
      "Created step text_to_image_step [011807ad][084a4455-76ca-424e-9ac9-da5dab4865d7], (This step will run and generate new outputs)\n",
      "Created step Estimator_coloring_step [d0777e9c][4e2cb8d6-03fc-43b5-a5a3-26d25f5bac8f], (This step will run and generate new outputs)\n",
      "Using data reference finetunedGPTModel for StepId [f567eedf][290212f9-9822-4507-b12d-f94c7b4b2969], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference coco for StepId [4950fee6][3b008c6a-fd9f-4adb-9065-5d40e43a2cfd], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference coco_AttnGAN2 for StepId [12901955][8a824f1e-c48b-4371-a335-2a754ca944bb], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference text_encoder100 for StepId [84ce7549][bb750316-709e-4125-8165-204cb1bea2af], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference photo_wct for StepId [61dca520][efa31c55-6adc-4e3f-bdfb-f2c77cdfdbb3], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference WikiArt_Emotions for StepId [cc078def][35d46802-fad0-40f5-a512-6aded6863b23], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: e630bd4b-47a9-4cd9-8dfb-bb659b7337d2\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "pipeline_exp = Experiment(ws,'Auria_Pipeline_Three').submit(auria_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 \n",
    "\n",
    "# Publishing it as a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The published pipeline ID is 25ab721b-1c39-444f-9730-7a045611af65\n"
     ]
    }
   ],
   "source": [
    "published_training_pipeline = auria_pipeline.publish(name=\"Auria_Pipeline_SP\",\n",
    "                                                        description=\"This new pipeline is the creative pursuit of Auria\")\n",
    "print(\"The published pipeline ID is {}\".format(published_training_pipeline.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d258ff0a31f24c2fbfb4841c3ae98114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_exp).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
